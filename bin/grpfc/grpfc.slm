#!/bin/bash
# 这里指定作业名称，注意vasp的输入文件无需特意指定
#SBATCH --job-name=test

# 提交到哪个队列（分区）
#SBATCH --partition=E5-2696V4

# 使用多少个节点
#SBATCH --nodes=1

# 每个节点使用多少核 强烈注意：核数必须为该队列单个节点的核数
#SBATCH --ntasks-per-node=44

# 生成错误和输出文件
#SBATCH --error=%j.err
#SBATCH --output=%j.out

# 以下行如果不懂，可以不管，按默认的即可。如果你知道其含义的话，可以进行自定义修改。

# 定义PFC程序安装目录
GRPFC="$HOME/bin/grpfc"

# Width, unit: ang
W=200

# Height, unit: ang
H=200

# Number of grains
N=10

# Radius of seed
R=1.5

# 以下生成MPI的nodelist
CURDIR=`pwd`
rm -rf $CURDIR/nodelist.$SLURM_JOB_ID
NODES=`scontrol show hostnames $SLURM_JOB_NODELIST`
for i in $NODES
do
echo "$i:$SLURM_NTASKS_PER_NODE" >> $CURDIR/nodelist.$SLURM_JOB_ID
done
# 生成nodelist结束


# PF程序主体
######################################
WW=`awk 'BEGIN{print int(1024/243*'$W')}'`
HH=`awk 'BEGIN{print int(1024/243*'$H')}'`
NN=$N
RR=$R

echo "WW=$WW, HH=$HH, NN=$NN RR=$RR"

cp $GRPFC/source/step* ./
sed -i "s@WW@$WW@g" step1.in
sed -i "s@HH@$HH@g" step1.in
sed -i "s@NN@$NN@g" step1.in
sed -i "s@RR@$RR@g" step1.in

sed -i "s@WW@$WW@g" step2.in
sed -i "s@HH@$HH@g" step2.in

mpirun -genv I_MPI_FABRICS_LIST=tcp -machinefile $CURDIR/nodelist.$SLURM_JOB_ID $GRPFC/pfc step1
mpirun -genv I_MPI_FABRICS_LIST=tcp -machinefile $CURDIR/nodelist.$SLURM_JOB_ID $GRPFC/pfc step2
java -jar $GRPFC/coordinator.jar step2-t\:10000.dat $WW $HH 0.7 0.7 7.3 2.46 step2-t\:10000.xy step2-t\:10000.nh
java -jar $GRPFC/plotter.jar step1-t:# step1-t:# $WW $HH 0 1000 10000
java -jar $GRPFC/plotter.jar step2-t:# step2-t:# $WW $HH 0 1000 10000
awk '{print $1+1,1,$2,$3,0}' step2-t\:10000.xy > graphene.xyz
atomN=`tail -1 graphene.xyz |awk '{print $1}'`
sed -i "1i\ " graphene.xyz
sed -i "1i$atomN" graphene.xyz

# 运行完后清理nodelist
rm -rf $CURDIR/nodelist.$SLURM_JOB_ID
